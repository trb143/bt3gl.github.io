<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>chmod +x singularity.sh</title><link>http://bt3gl.github.io/</link><description></description><atom:link href="http://bt3gl.github.io/feeds/ai-ml-review.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 30 Jul 2016 00:00:00 -0400</lastBuildDate><item><title>ICYM AI &amp; ML - Week #30 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-30-of-2016.html</link><description>&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"&gt;Image classification (AlexNet)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1409.1556.pdf"&gt;Image classification (VGGNet)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1207.0580.pdf"&gt;Dropout and regularization&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1503.03832v3.pdf"&gt;Metric learning (FaceNet)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1512.03385v1.pdf"&gt;Very deep networks (ResNet)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;*&lt;a href="https://arxiv.org/pdf/1409.0473v7.pdf"&gt;RNNs, LSTMs, GRUs - machine translation with alignment&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1412.5903v5.pdf"&gt;Text recognition&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/pdf/1512.02595v1.pdf"&gt;Speech recognition (DeepSpeech 2)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1508.06576v2.pdf"&gt;Artistic style transfer&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1511.08228v3.pdf"&gt;Neural GPUs&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://people.csail.mit.edu/kalyan/AI2_Paper.pdf"&gt;AI2: Training a big data machine to defend (Kalyan, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://download.tensorflow.org/paper/whitepaper2015.pdf"&gt;Tensor Flow Whitepaper, (Abadi, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://lvdmaaten.github.io/publications/papers/Torchnet_2016.pdf"&gt;Torchnet: An Open-Source Platform for (Deep) Learning Research, (Collobert, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html"&gt;Using Keras and Deep Q-Network to Play FlappyBird&lt;/a&gt;. Hands-on on Google DeepMind's Deep Q-Network.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;. This is a 2-years-old article, but a very well-written high-level explanation of the topology of low-dimensional NNs. "&lt;em&gt;The task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.&lt;/em&gt;"&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-08-Backprop/"&gt;Calculus on Computational Graphs: Backpropagation&lt;/a&gt;. Backpropagation explaned in a very well-written text.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks.&lt;/a&gt;. Another hit :).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://colah.github.io/posts/2015-01-Visualizing-Representations/"&gt;Visualizing Representations: Deep Learning and Human Beings.&lt;/a&gt; Another Christopher Olah's great post, now on NN's different layers representations, tanging some philosophic aspects of it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/cnnembed/"&gt;Karpathy's t-SNE visualization of CNN codes.&lt;/a&gt; He takes the 50k ILSVRC 2012 validation images, extracts the 4096-dimensional fc7 CNN features using Caffe and then uses Barnes-Hut t-SNE to compute a 2-dimensional embedding that respects the high-dimensional (L2) distances. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://blogs.nvidia.com/blog/2016/01/12/accelerating-ai-artificial-intelligence-gpus/"&gt;NVIDIA's Accelerating AI with GPUs: A New Computing Model&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://code.facebook.com/posts/580706092103929/lighting-the-way-to-deep-machine-learning/"&gt;Torchnet: Lighting the way to deep machine learning&lt;/a&gt;. "&lt;em&gt;&lt;a href="https://github.com/torchnet/torchnet"&gt;Torchnet&lt;/a&gt; is different from frameworks such as Caffe, Chainer, TensorFlow, and Theano, in that it does not focus on performing efficient inference and gradient computations in deep networks. Instead, Torchnet provides a framework on top of a deep learning framework that makes rapid experimentation easier.&lt;/em&gt;"&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44921.pdf"&gt;Large-Scale Deep Learning for Intelligent Computer Systems by Jeff Dean&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground"&gt;Understanding neural networks with TensorFlow Playground&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html"&gt;Karpathy's Convnetjs viz tool.&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=JeBkUtYvBBM"&gt;Prof Adrian Owen on The Search for Consciousness: detecting awareness in the vegetative state (2015)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Ics9CjRSMfc"&gt;Baidu AI Composer&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remember that the hidden layer learns a representation so that the data is linearly separable, so that's is how you do separate a spiral two-dimensional dataset using Tensorflow playground and Convnetjs:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With tanh:&lt;/p&gt;
&lt;p&gt;&lt;img alt="tahn2" height="300px" src="./tensor_flow_playground/tanh2.png" width="400px" /&gt;  &lt;img alt="tahn11" height="300px" src="./tensor_flow_playground/tan1.png" width="400px" /&gt;   &lt;img alt="tan2" height="300px" src="./tensor_flow_playground/tan2.png" width="400px" /&gt;   &lt;img alt="tan3" height="300px" src="./tensor_flow_playground/tan3.png" width="400px" /&gt; &lt;/p&gt;
&lt;p&gt;With ReLU:&lt;/p&gt;
&lt;p&gt;&lt;img alt="relu2" height="300px" src="./tensor_flow_playground/relu2.png" width="400px" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;That's is how you do not separate a spiral two-dimensional dataset:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="linear" height="300px" src="./tensor_flow_playground/linear.png" width="400px" /&gt; &lt;img alt="relu_no" height="300px" src="./tensor_flow_playground/relu_no.png" width="400px" /&gt; &lt;img alt="sigmoid" height="300px" src="./tensor_flow_playground/sigmoid.png" width="400px" /&gt;  &lt;img alt="relu_no2" height="300px" src="./tensor_flow_playground/relu_no2.png" width="400px" /&gt;  &lt;img alt="relu_no3" height="300px" src="./tensor_flow_playground/relu_no3.png" width="400px" /&gt;  &lt;img alt="relu_no4" height="300px" src="./tensor_flow_playground/relu_no4.png" width="400px" /&gt; &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 30 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-30:icym-ai-ml-week-30-of-2016.html</guid></item><item><title>ICYM AI &amp; ML - Week #29 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-29-of-2016.html</link><description>&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1409.4842.pdf"&gt;Going deeper with Convolutions (Szegedy, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=yxxRAHVtafI"&gt;The Science of Talking with Computers&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=NK6O8CtI2D4"&gt;Megan Smith: Perspectives on artificial intelligence from the White House&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=6eBpjEdgSm0"&gt;NVIDIA Deep Learning Course: Class #1 – Introduction to Deep Learning&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=u2t77mQmJiY"&gt;A genetic algorithm learns how to fight!&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 23 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-23:icym-ai-ml-week-29-of-2016.html</guid></item><item><title>ICYM AI &amp; ML - Week #28 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-28-of-2016.html</link><description>&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.benjamintd.com/blog/spynet/?utm_campaign=Artificial%2BIntelligence%2BWeekly&amp;amp;utm_medium=web&amp;amp;utm_source=Artificial_Intelligence_Weekly_42"&gt;Teaching an AI to write Python code with Python code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://efavdb.com/deep-learning-with-jupyter-on-aws/"&gt;Starting DL with Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.gc2fcdcce7_216_515"&gt;DIY Deep Learning for Vision:  a Hands-On Tutorial with Caffe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html"&gt;Wide &amp;amp; Deep Learning: Better Together with TensorFlow&lt;/a&gt;. &lt;em&gt;Can we teach computers to learn like humans do, by combining the power of memorization and generalization?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf"&gt;Mastering the Game of Go with Deep Neural Networks and Tree Search&lt;/a&gt;. Basically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Values networks to evaluate board positions and policy networks to select moves.&lt;/li&gt;
&lt;li&gt;Trained with supervised learning from human expert games and reinforcement learning from games of self-play.&lt;/li&gt;
&lt;li&gt;NN playS Go at the level of state-of-art Monte-Carlo tree search that simulate thousands of random games of self-play.&lt;/li&gt;
&lt;li&gt;New search algorithm that combines Monte-Carlo simulation with value and policy network.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1607.02533v1.pdf"&gt;Adversarial Examples in the Physical World (Kurakin, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf"&gt;Deep Residual Networks, Kaiming He, Facebook AI Research&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Resources_files/AlphaGo_IJCAI.pdf"&gt;AlphaGo Presentation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XkltShNd6XE"&gt;Prof. Jürgen Schmidhuber - True Artificial Intelligence Will Change Everything&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;"All games of perfect information have an optimal value function which determines the outcome of the game".&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://diogenes.greedbag.com/buy/ghost-lanes-0/"&gt;Post-Rock as it best: Ghost Lanes&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 16 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-16:icym-ai-ml-week-28-of-2016.html</guid></item></channel></rss>