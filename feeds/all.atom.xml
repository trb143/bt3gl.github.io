<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>chmod +x singularity.sh</title><link href="http://bt3gl.github.io/" rel="alternate"></link><link href="http://bt3gl.github.io/feeds/all.atom.xml" rel="self"></link><id>http://bt3gl.github.io/</id><updated>2016-08-27T00:00:00-04:00</updated><entry><title>This week in AI &amp; ML &amp; Hacking - #34 of 2016</title><link href="http://bt3gl.github.io/this-week-in-ai-ml-hacking-34-of-2016.html" rel="alternate"></link><updated>2016-08-27T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-08-27:this-week-in-ai-ml-hacking-34-of-2016.html</id><summary type="html">&lt;p&gt;&lt;img alt="cyber" height="300px" src="./cyberpunk/7.gif" width="400px" /&gt;&lt;/p&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1608.05343"&gt;Decoupled Neural Interfaces using Synthetic Gradients&lt;/a&gt;. New DeepMind's paper reviewing backpropagation, using a modeled synthetic gradient in place of true backpropagated error gradients. Backpropagation is a a bottleneck in DNN, so the idea is instead use an asynchronous estimator, that would be obtained by supervised training of another mini neural network (a fully-connected NN regressor with 0-3 layers). Some speedup was showed in DeepMind’s hardware, but still raising questions on whether this would add any improvement on low-end GPUs setup.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1608.05148v1.pdf"&gt;Full Resolution Image Compression with Recurrent
Neural Networks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1608.03983v2.pdf"&gt;SGDR: Stochastic Gradient Descent with Restarts&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1608.04980v1.pdf"&gt;Mollifying Networks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://ai.stanford.edu/~nilsson/QAI/qai.pdf"&gt;The quest for Artificial Intelligence&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Good'n'old&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1407.7906"&gt;How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1605.02026.pdf"&gt;Training Neural Networks Without Gradients:
A Scalable ADMM Approach&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/abs/1506.08473"&gt;Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1506.02025.pdf"&gt;Spatial Transformer Networks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1412.2306v2.pdf"&gt;Deep Visual-Semantic Alignments for Generating Image Descriptions&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1406.2661v1.pdf"&gt;Generative Adversarial Nets&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.sixthtone.com/news/weiqi-players-go-flow"&gt;‘Weiqi’ Players Go With the Flow&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@philjama/how-tensors-advance-human-technology-3831bff0906#.mp19g9px5"&gt;How Tensors Advance Human Technology&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://pemami4911.github.io/blog_posts/2016/08/21/ddpg-rl.html"&gt;Deep Deterministic Policy Gradients in TensorFlow&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/"&gt;RNNs in Tensorflow, a Practical Guide&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@ivydatascience/landscape-of-deep-learning-frameworks-aae34564cab#.m9r6p2uvs"&gt;Landscape of Deep Learning Frameworks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue#.V7hqFpKnLPo.google_plusone_share"&gt;End-to-End Deep Learning for Self-Driving Cars&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nlpers.blogspot.com/2016/08/debugging-machine-learning.html"&gt;Debugging machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.googleblog.com/2016/08/text-summarization-with-tensorflow.html"&gt;Text summarization with TensorFlow&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/"&gt;An introduction to Generative Adversarial Networks (with code in TensorFlow)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://deliprao.com/archives/191"&gt;Is BackPropagation Necessary?&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.fastforwardlabs.com/post/149329060653/under-the-hood-of-the-variational-autoencoder-in"&gt;Under the Hood of the Variational Autoencoder (in Prose and Code)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;[Reinforcement Learning and DQN, learning to play from pixels](https://rubenfiszel.github.io/posts/rl4j/2016-08-24-Reinforcement-Learning-and-DQN.html.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/facebookresearch/fastText"&gt;fastText, Library for fast text representation and classification.&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/bamos/dcgan-completion.tensorflow?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue"&gt;Image Completion with Deep Learning in TensorFlow&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=GccsFBQm-d4"&gt;TensorFlow: Demystifying Deep Learning with Visualizations&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=ohmajJTcpNk"&gt;Face2Face: Real-time Face Capture and Reenactment of RGB Videos (CVPR 2016 Oral)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=2FmcHiLCwTU"&gt;TensorFlow in 5 Minutes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</summary></entry><entry><title>This week in AI &amp; ML &amp; Hacking - #33 of 2016</title><link href="http://bt3gl.github.io/this-week-in-ai-ml-hacking-33-of-2016.html" rel="alternate"></link><updated>2016-08-19T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-08-19:this-week-in-ai-ml-hacking-33-of-2016.html</id><summary type="html">&lt;p&gt;&lt;a href="https://www.reddit.com/r/Cyberpunk/comments/4xun92/would_anyone_want_more_photoshops_like_this/"&gt;&lt;img alt="cyber" height="300px" src="./cyberpunk/6.png" width="400px" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1608.05343.pdf"&gt;Decoupled Neural Interfaces using Synthetic Gradients&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1607.02444v1.pdf"&gt;Explaining Deep Convolutional Neural Networks on Music Classification&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cims.nyu.edu/~schlacht/CNNFluids.htm"&gt;Accelerating Eulerian Fluid Simulation With Convolutional Networks&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1608.02908?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue"&gt;Residual Networks of Residual Networks: Multilevel Residual Networks&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classic references on &lt;strong&gt;Deep Reinforcement Learning&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"&gt;Playing Atari with Deep Reinforcement Learning, (Mnih &lt;em&gt;et. al&lt;/em&gt; 2014)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://home.uchicago.edu/~arij/journalclub/papers/2015_Mnih_et_al.pdf"&gt;Human-level control through deep reinforcement learning (Mnih &lt;em&gt;et. al&lt;/em&gt; 2015)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.inf.elte.hu/lorincz/Files/RL_2006/SuttonBook.pdf"&gt;Reinforcement Learning: An Introduction&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.nervanasys.com/demystifying-deep-reinforcement-learning/
https://www.youtube.com/watch?v=Fsh1qMTg1xI"&gt;Demystifying Deep Reinforcement Learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://media.nips.cc/Conferences/2015/tutorialslides/SuttonIntroRL-nips-2015-tutorial.pdf"&gt;Introduction to Reinforcement Learning with Function Approximation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.cse.unsw.edu.au/~cs9417ml/RL1/index.html"&gt;Reinforcement Learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html"&gt;UCL Course on RL&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://artint.info/html/ArtInt_262.html"&gt;Reinforcement Learning&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://singularityhub.com/2016/08/14/ibms-new-artificial-neurons-a-big-step-toward-brain-like-computers/"&gt;IBM’s New Artificial Neurons a Big Step Toward Powerful Brain-Like Computers&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.quora.com/What-are-some-recent-and-potentially-upcoming-breakthroughs-in-deep-learning"&gt;Quora's 'What are some recent and potentially upcoming breakthroughs in deep learning?'&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.engadget.com/2016/08/16/the-next-wave-of-ai-is-rooted-in-human-culture-and-history/"&gt;The next wave of AI is rooted in human culture and history&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.engadget.com/2016/08/15/technological-singularity-problems-brain-mind/"&gt;We don't understand AI because we don't understand intelligence&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue"&gt;An Intuitive Explanation of Convolutional Neural Networks&lt;/a&gt;. Great.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1608.03282v1.pdf"&gt;Instagram photos reveal predictive markers of depression&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://shakirm.com/slides/DLSummerSchool_Aug2016_compress.pdf"&gt;Building Machines that Imagine and Reason&lt;/a&gt;. Nice introduction to Deep Generative Models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aetros.com/"&gt;Aetros&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/berlius/artificial-intelligence"&gt;Docker image for artificial intelligence&lt;/a&gt;. Auralisation of a CNN by converting the learned convolutional features that are obtained from deconvolution into audio signals.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/aymericdamien/TopDeepLearning?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue"&gt;A list of popular github projects related to deep learning&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=xN1d3qHMIEQ"&gt;Inside DeepMind&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?utm_campaign=Revue%20newsletter&amp;amp;utm_medium=Newsletter&amp;amp;utm_source=revue&amp;amp;v=InYNSzVblZQ"&gt;RE•WORK Interview with Yoshua Bengio - Deep Learning Summit, Boston, 2016&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://artificialintelligencenow.com/"&gt;The Social and Economic Implications of Artificial Intelligence Technologies in the Near-Term&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Fun&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.engadget.com/2016/08/13/duoskin-high-tech-flash-tattoos/"&gt;MIT's and Microsoft's flash tattoos can control gadgets&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/176714277"&gt;An Autonomous Agent Choreo&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=wgSZA3NPpBs&amp;amp;index=2&amp;amp;list=PLrfcruGtplwGKzxDI_Ne06NlpOKt-yonZ"&gt;2016 Isaac Asimov Memorial Debate: Is the Universe a Simulation?&lt;/a&gt;. &lt;strong&gt;Real&lt;/strong&gt; scientists discussing the topic.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/artificial/comments/4xbuiy/if_we_believe_humans_are_able_to_create_agi_and/"&gt;Reddit 'If we believe, humans are able to create AGI, and consequently ASI, we are mostly likely in a simulation already' funny thread.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/artificial/comments/4xtile/why_elon_musk_says_were_living_in_a_simulation/"&gt;Reddit 'We are Living in Simulation' funny thread&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.scientificamerican.com/article/20-big-questions-about-the-future-of-humanity/"&gt;20 Big Questions about the Future of Humanity&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Visualizing the network for MNIST Database of handwritten&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://scs.ryerson.ca/~aharley/vis/fc/"&gt;This tool&lt;/a&gt; allows you to vizualize a NN trained with MNIST to recognize digits. There you can see the ouput layer (top), followed by the second hidden layer, the first hidden layer, and the input layer. &lt;/p&gt;
&lt;p&gt;Interesting examples:&lt;/p&gt;
&lt;p&gt;&lt;img alt="mnist" height="300px" src="./mnist/1.png" width="400px" /&gt;
&lt;img alt="mnist" height="300px" src="./mnist/2.png" width="400px" /&gt;
&lt;img alt="mnist" height="300px" src="./mnist/3.png" width="400px" /&gt;
&lt;img alt="mnist" height="300px" src="./mnist/4.png" width="400px" /&gt;
&lt;img alt="mnist" height="300px" src="./mnist/5.png" width="400px" /&gt;
&lt;img alt="mnist" height="300px" src="./mnist/6.png" width="400px" /&gt;&lt;/p&gt;
&lt;h4&gt;33 is an awesome number.&lt;/h4&gt;
&lt;p&gt;&lt;img alt="cyberpunk" height="600px" src="./draws/gan.png" width="900px" /&gt;&lt;/p&gt;</summary></entry><entry><title>This week in AI &amp; ML &amp; Hacking - #32 of 2016</title><link href="http://bt3gl.github.io/this-week-in-ai-ml-hacking-32-of-2016.html" rel="alternate"></link><updated>2016-08-14T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-08-14:this-week-in-ai-ml-hacking-32-of-2016.html</id><summary type="html">&lt;p&gt;&lt;img alt="cyberpunk" height="300px" src="./cyberpunk/5.jpg" width="400px" /&gt;&lt;/p&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.tomeveritt.se/papers/AGI16-sm.pdf"&gt;Self-Modification of Policy and Utility Function in
Rational Agents (Everitt, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/dmorr-google/wiki-reading"&gt;WIKIREADING: A Novel Large-scale Language Understanding Task
over Wikipedia (Hewlett, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://users.dsic.upv.es/~flip/EGPAI2016/papers/EGPAI_2016_paper_9.pdf"&gt;Evaluation of General-Purpose Artificial Intelligence: Why, What &amp;amp; How, (Bieger, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aclweb.org/anthology/P/P16/P16-1013.pdf"&gt;Learning the Curriculum with Bayesian Optimization
for Task-Specific Word Representation Learning, (Tsvetkov, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aclweb.org/anthology/P/P16/P16-1015.pdf"&gt;Generalized Transition-based Dependency Parsing
via Control Parameters, (Bohnet, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aclweb.org/anthology/P/P16/P16-1057.pdf"&gt;Latent Predictor Networks for Code Generation, (Ling, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aclweb.org/anthology/P/P16/P16-1059.pdf"&gt;Collective Entity Resolution with Multi-Focal Attention, (Globerson, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aclweb.org/anthology/P/P16/P16-1231.pdf"&gt;Globally Normalized Transition-Based Neural Networks, (Andor, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1605.02817v1.pdf"&gt;Unethical Research: How to Create a Malevolent Artificial Intelligence, (Pistono, &lt;em&gt;et. al&lt;/em&gt;, 2016))&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1606.00652v1.pdf"&gt;Death and Suicide in Universal Artificial Intelligence, (Martin, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1043.pdf"&gt;Easy Questions First?
A Case Study on Curriculum Learning for Question Answering, (Sachan, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1035.pdf"&gt;Query Expansion with Locally-Trained Word Embeddings (Diaz, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1049.pdf"&gt;DocChat: An Information Retrieval Approach for Chatbot Engines
Using Unstructured Documents, (Yan, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1224.pdf"&gt;Learning Language Games through Interaction, (Wang, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1170.pdf"&gt;Generating Natural Questions About an Image, (Mostafazadeh, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://aclweb.org/anthology/P/P16/P16-1186.pdf"&gt;Strategies for Training Large Vocabulary Neural Language Models, (Chen, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/karpathy/paper-notes"&gt;Andrej Karpathy's papers notes.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;News&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.technologyreview.com/s/602094/ais-language-problem/?utm_campaign=add_this&amp;amp;utm_source=twitter&amp;amp;utm_medium=post"&gt;AI’s Language Problem&lt;/a&gt;. "One reason that understanding language is so difficult for computers and AI systems is that words often have meanings based on context and even the appearance of the letters and words. In the images that accompany this story, several artists demonstrate the use of a variety of visual clues to convey meanings far beyond the actual letters."&lt;/li&gt;
&lt;li&gt;&lt;a href="http://bamos.github.io/2016/08/09/deep-completion/"&gt;Image Completion with Deep Learning in TensorFlow&lt;/a&gt;. Great detailed tutorial using a DCGAN.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://techcrunch.com/2016/08/08/machine-learning-and-molecular-tinder-may-change-the-game-for-oled-screens/"&gt;Machine learning and “molecular Tinder” may change the game for OLED screens&lt;/a&gt;. Interesting article on how ML on molecules is helping to push the OLED screens industry.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.nextplatform.com/2016/08/08/deep-learning-chip-upstart-set-take-gpus-task/"&gt;Deep Learning Chip Upstart Takes GPUs to Task&lt;/a&gt;. Nervana System’s pitch, including a comparison of Pascal and Maxwell TitanX.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://futureoflife.org/background/aimyths/"&gt;Top Myths about Advanced AI from Future of Life Institute&lt;/a&gt;. An interesting (and maybe alarmist) review of GAI myths and (maybe) facts.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://techcrunch.com/2016/08/13/hearing-is-like-seeing-for-our-brains-and-for-machines/?ncid=rss"&gt;Hearing is like seeing for our brains and for machines&lt;/a&gt;. Think synesthesia. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.technologyreview.com/s/602115/machine-learning-algorithm-combs-the-darknet-for-zero-day-exploits-and-finds-them/?set=602116&amp;amp;utm_content=buffer49be6&amp;amp;utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=buffer"&gt;Machine-Learning Algorithm Combs the Darknet for Zero Day Exploits, and Finds Them&lt;/a&gt;. "The first machine-based search of online hacker marketplaces identifies over 300 significant cyberthreats every week."&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gab41.lab41.org/exploring-pipelines-68f900625bd4#.njpynqaon"&gt;Exploring Pipelines&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.facebook.com/blog/cat-people-dog-people/?_fb_noscript=1"&gt;Cat People, Dog People&lt;/a&gt;. Funny post exploring characteristics (features) of "dog people" and "cat people" on Facebook. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.fastforwardlabs.com/post/148842796218/introducing-variational-autoencoders-in-prose-and"&gt;Introducing Variational Autoencoders (in Prose and Code)&lt;/a&gt;. Good introduction to autocoders.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://defensesystems.com/articles/2016/08/12/quantum-center-upgrade-lockheed-usc.aspx"&gt;Quantum computing center upgrades to focus on AI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/"&gt;Google Brain's AMA&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/@camrongodbout/recurrent-neural-networks-for-beginners-7aca4e933b82#.3ofku68fe"&gt;Recurrent Neural Networks for Beginners&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.nvidia.com/blog/2016/07/21/titan-x/?utm_campaign=Artificial%2BIntelligence%2BWeekly&amp;amp;utm_medium=email&amp;amp;utm_source=Artificial_Intelligence_Weekly_43"&gt;The New NVIDIA TITAN X&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://gab41.lab41.org/lab41-reading-group-deep-compression-9c36064fb209#.jzw0hmaqs"&gt;Lab41 Reading Group: Deep Compression&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://blog.forallsecure.com/2016/02/09/unleashing-mayhem/"&gt;Unleashing the Mayhem CRS (DARPA CGC).&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools and Apps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://moralmachine.mit.edu/"&gt;MIT's Moral Machine.&lt;/a&gt; "A platform for gathering a human perspective on moral decisions made by machine intelligence".&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/getzerofox/SNAP_R"&gt;A machine learning based social media pen-testing tool&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conference Slides&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://sites.google.com/site/deeplearningsummerschool2016/speakers"&gt;The Deep Learning Summer School&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=g_ypY4Qjj1Y"&gt;Drone Dreaming&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=LzC8NkTZAF4"&gt;Neural GPU Learned Algorithms&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://vimeo.com/170189199"&gt;AI, Deep Learning, and Machine Learning: A Primer&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=3otrUaWcLYU"&gt;Most robots dancing simultaneously - Guinness World Records&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Fun&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://curatedai.com/"&gt;CuratedAI, A literary magazine written by machines, for people&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.businessinsider.com/william-gibson-the-peripheral-interview-business-insider-2016-8"&gt;William Gibson talks about 'The Peripheral,' the power of Twitter, and his next book set in today's Silicon Valley&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.wired.com/2016/08/no-mans-sky-review/"&gt;No Man's Sky is out!&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=8pJD-IgUTfw"&gt;Scann-tec - Hope&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="cyberpunk" height="600px" src="./draws/nn1.png" width="900px" /&gt;
&lt;img alt="cyberpunk" height="600px" src="./draws/nn2.png" width="900px" /&gt;
&lt;img alt="cyberpunk" height="600px" src="./draws/nn3.png" width="900px" /&gt;&lt;/p&gt;</summary></entry><entry><title>This week in AI &amp; ML &amp; Hacking - #31 of 2016</title><link href="http://bt3gl.github.io/this-week-in-ai-ml-hacking-31-of-2016.html" rel="alternate"></link><updated>2016-08-06T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-08-06:this-week-in-ai-ml-hacking-31-of-2016.html</id><summary type="html">&lt;p&gt;&lt;img alt="cyberpunk" height="300px" src="./cyberpunk/1.jpeg" width="400px" /&gt;&lt;/p&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.blackhat.com/docs/us-16/materials/us-16-Wolff-Applied-Machine-Learning-For-Data-Exfil-And-Other-Fun-Topics.pdf"&gt;Black Hat 2016: Applied Machine Learning for Data Exfil and Other Fun Topics&lt;/a&gt;. Cylance's researchers show some examples of how they apply K-means, Decision Trees, and Markov Chains to security's problems.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.blackhat.com/docs/us-16/materials/us-16-Berlin-An-AI-Approach-To-Malware-Similarity-Analysis-Mapping-The-Malware-Genome-With-A-Deep-Neural-Network.pdf"&gt;Black Hat 2016: An AI approach to Malware Similarity Analysis&lt;/a&gt;. Invincea Lab's Researcher shows how they use supervised learning approaches to extract features in Malware data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=T1O3ikmTEdA&amp;amp;feature=youtu.be&amp;amp;t=10m56s"&gt;Peter Norvig: How Computers Learn&lt;/a&gt;. Great introduction and review of AI and ML's history.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aiimpacts.org/costs-of-extinction-risk-mitigation/"&gt;Costs of extinction risk mitigation&lt;/a&gt;. A Cost-Benefit Analysis of the extinction risk mitigation, claiming that the annual cost of reducing the probability of human extinction by 0.01% is within the range of $1.1 billion to $3.5 trillion. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html"&gt;Written Memories: Understanding, Deriving and Extending the LSTM&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8#.4on1g3268"&gt;(Self-titled) The best explanation of Convolutional Neural Networks on the Internet&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nuit-blanche.blogspot.com/2016/08/secure-group-testing.html"&gt;Secure Group Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.theverge.com/2016/7/13/12172904/facebook-ai-big-sur-machine-learning-prineville-data-center"&gt;Exploring Facebook’s massive, picture-painting AI brain&lt;/a&gt;. A 350,000-square-foot building  with Facebook’s most valuable artificial intelligence tools, Big Sur. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/1687861518126048/facebook-to-open-source-ai-hardware-design/?_fb_noscript=1"&gt;Facebook to open-source AI hardware design&lt;/a&gt;. Facebook's Open Compute Project GPU hardware contribution, FAIR, which has achieved lots of advancements in the development of AI training hardware.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/science/2016/07/algorithms-used-to-study-brain-activity-may-be-exaggerating-results/"&gt;Software faults raise questions about the validity of brain studies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://prefrontal.org/files/posters/Bennett-Salmon-2009.pdf"&gt;Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: An argument for multiple comparisons correction&lt;/a&gt;. Researchers show claims showing that the interpretation of functional MRI data is questionable.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sarahjamielewis.com/posts/adversarial-machine-learning.html"&gt;Adversarial Machine Learning for Security&lt;/a&gt;. A marvelous introduction to AML, with several references.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://deepdrive.io/"&gt;DeepDrive: self-driving car AI&lt;/a&gt;. DNN resources for self-driving car, including integration with OpenAI Gym.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://intelligence.org/2016/08/02/2016-summer-program-recap/"&gt;2016 summer program recap&lt;/a&gt;. A Colloquium Series on Robust and Beneficial AI (CSRBAI) at the MIRI office, co-hosted with the Oxford Future of Humanity Institute. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.benjamintd.com/blog/spynet/"&gt;Teaching an AI to write Python code with Python code&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1607.08022"&gt;Instance Normalization: The Missing Ingredient for Fast Stylization (Ulyanov, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.creativeai.net/posts/CjrYHppotnFXbeWW8/learning-semantic-deformation-flows-with-3d-convolutional"&gt;Learning Semantic Deformation Flows with 3D Convolutional Networks &lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Events&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/4v58b2/google_brain_will_be_doing_an_ama_in/"&gt;Google Brain will be doing an AMA in August 11st&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://norvig.com/ipython/README.html"&gt;List of IPython (Jupyter) Notebooks by Peter Norvig&lt;/a&gt;.  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cchio/deep-pwning"&gt;Deep Pwning: Metasploit for machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jcjohnson/cnn-benchmarks"&gt;Benchmarks for popular CNN models&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=GWn7vD2Ud3M"&gt;Build an Autoencoder in 5 Min&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="cyberpunk" height="600px" src="./draws/data1.png" width="900px" /&gt;
&lt;img alt="cyberpunk" height="600px" src="./draws/data2.png" width="900px" /&gt;
&lt;img alt="cyberpunk" height="600px" src="./draws/data3.png" width="900px" /&gt;&lt;/p&gt;</summary></entry><entry><title>The effects of Convolutional Neural Networks on a Hot Summer Night</title><link href="http://bt3gl.github.io/the-effects-of-convolutional-neural-networks-on-a-hot-summer-night.html" rel="alternate"></link><updated>2016-08-01T00:00:00-04:00</updated><author><name>Marina von Steinkirch</name></author><id>tag:bt3gl.github.io,2016-08-01:the-effects-of-convolutional-neural-networks-on-a-hot-summer-night.html</id><summary type="html">&lt;p&gt;&lt;img alt="dream" height="300px" src="./dream/d1.jpg" width="400px" /&gt;&lt;/p&gt;
&lt;p&gt;About an year ago, Google published a seminal paper named &lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"&gt;ImageNet Classification with Deep Convolutional Neural Networks&lt;/a&gt;, together with a &lt;a href="https://research.googleblog.com/2015/07/deepdream-code-example-for-visualizing.html"&gt;blog post&lt;/a&gt;, which became known as &lt;strong&gt;Inceptionism&lt;/strong&gt;. This work unveiled not only a new way of composing hallucinating artistic pictures, but astonishing new insights on &lt;strong&gt;how convolutional neural networks work&lt;/strong&gt;. Now we are able to see what each hidden layer in the net has learned, or in a more philosophical explanation, what the &lt;strong&gt;machine sees&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Convolutional Neural Networks take an image (a vector of pixels) as input, and transform the image through several layers of nonlinear functions (kind of how &lt;a href="https://en.wikipedia.org/wiki/Kernel_(image_processing)"&gt;kernels&lt;/a&gt; work). The &lt;strong&gt;dream images&lt;/strong&gt; are just a &lt;strong&gt;gradient ascent process&lt;/strong&gt; that minimizes the &lt;strong&gt;L2 norm&lt;/strong&gt; of activation functions of some deep neural network layer. &lt;/p&gt;
&lt;p&gt;More specifically, in the task of image classification:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;lower levels&lt;/strong&gt; reveal edge-like regions in the images (such as corners),&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;intermediate layers&lt;/strong&gt; represent basic shapes and components of objects (such as eyes),&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;the final layers&lt;/strong&gt; compose the complete interpretation (such as dog), but in a &lt;a href="https://www.reddit.com/r/deepdream/comments/3cawxb/what_are_deepdream_images_how_do_i_make_my_own/"&gt;psychedelic way&lt;/a&gt;. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Google released the code of its &lt;a href="https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet"&gt;GoogLeNet model&lt;/a&gt;, which is trained trained on &lt;a href="http://www.image-net.org/"&gt;ImageNet dataset&lt;/a&gt;.  I slightly adapted it &lt;a href="https://github.com/bt3gl/Machine-Learning-Resources/tree/master/Deep_Art/deepdream"&gt;here&lt;/a&gt;, adding some instructions on how one can play with it in a AWS GPU instance.&lt;/p&gt;
&lt;p&gt;Examples of &lt;strong&gt;deep dream&lt;/strong&gt; with the following layers:&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;inception_3b/5x5_reduce&lt;/em&gt; (lower levels):&lt;/h4&gt;
&lt;p&gt;&lt;img alt="dream" height="450px" src="./dream/d12.jpeg" width="550px" /&gt;&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;inception_4c/output&lt;/em&gt; (higher levels):&lt;/h4&gt;
&lt;p&gt;&lt;img alt="dream" height="450px" src="./dream/d11.jpeg" width="550px" /&gt;&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;inception_3b/output&lt;/em&gt; (controlled dreams):&lt;/h4&gt;
&lt;p&gt;&lt;img alt="dream" height="450px" src="./dream/d3.jpg" width="550px" /&gt;
&lt;img alt="dream" height="450px" src="./dream/d13.jpeg" width="550px" /&gt;&lt;/p&gt;
&lt;h3&gt;Enjoy!&lt;/h3&gt;
&lt;p&gt;&lt;img alt="dream" height="300px" src="./dream/1.jpg" width="400px" /&gt;&lt;/p&gt;</summary></entry></feed>